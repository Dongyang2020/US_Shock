{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNskIn3RjPb5SEbsNgN9m+I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dpv9nxH3kz3j"},"source":["## Detrend & Standardize"]},{"cell_type":"code","source":["! pip install pyts\n","from pyts.decomposition import SingularSpectrumAnalysis\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"5NLIoX8POFvQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixA4jKu_cmGr"},"outputs":[],"source":["# -- format and save agricultural data\n","ratio_fmt = pd.read_csv(fname[0])\n","\n","# -- loop for five variables\n","for j in range(5):\n","  vb0 = pd.read_csv(fname[j])\n","  # filter useless rows\n","  vb0 = ratio_fmt[['State','County']].merge(vb0, how='left')\n","\n","  vb = vb0.drop(columns=['State', 'County'])\n","  vb_t = vb.copy().T\n","  # -- detrend \n","  vb_ny = vb.to_numpy()\n","\n","  for i in range(len(vb)):\n","    # i=0\n","    to_dt=vb_ny[i,:][~np.isnan(vb_ny[i])].reshape(1,-1)\n","    # Singular Spectrum Analysis\n","    ssa = SingularSpectrumAnalysis(window_size=10)\n","    vb_ssa = ssa.fit_transform(to_dt)\n","    back_value = to_dt[0] - vb_ssa[0]\n","    # find the index of non-NA rows\n","    slt_ind = vb_t[i].index[~vb_t[i].isnull()]\n","    vb_t.loc[slt_ind,i] = back_value\n","\n","  # -- tranpose back to normal format\n","  vb_to_st = vb_t.copy().T\n","  \n","  # -- standardize\n","  vb_st=vb_to_st.sub(vb_to_st.mean(1), axis=0).div(vb_to_st.std(1), axis=0)\n","  vb_st[['State', 'County']] = vb0[['State', 'County']]\n","  \n","  # -- format the final rows to merge\n","  vb_to_m = vb_st.melt(id_vars=['State','County'])\n","  vb_to_m = vb_to_m.rename(columns={'variable': 'year', 'value': vname2[j]})\n","\n","  vb_to_m = vb_to_m.dropna()\n","  vb_to_m[\"year\"]= vb_to_m[\"year\"].str[-4:]\n","  vb_to_m['year'] =vb_to_m['year'].astype(int)\n","  vb_one = vb_to_m.merge(county_code[['State',\t'state',\t'County',\t'county']],on=['State','County']).drop_duplicates()\n","\n","  oname[j] = vb_one.copy() \n","  oname[j].to_csv(sname_dtst[j])\n","  \n"]},{"cell_type":"markdown","metadata":{"id":"mCZ5LaTxy4D2"},"source":["# RandomForest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-yxCG4Zzel9"},"outputs":[],"source":["from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37rrw6aC1kMG"},"outputs":[],"source":["# -- creat feature and target variables\n","feature = df[df.columns[7:]]\n","target = df['vrb']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPoav_IZ1kMG"},"outputs":[],"source":["# -- create train/test sets\n","feat_tr, feat_te, targ_tr, targ_te = train_test_split(feature, target, \n","                                                          test_size=0.2, random_state=333)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29rxrmdV1kMG"},"outputs":[],"source":["# -- select the parameter(s) to tune and the values to try\n","tuned_parameters = [{\"min_samples_leaf\" : [5, 10, 50], \n","                     \"max_features\":[5, 8, 11],\n","                     \"max_depth\":[40, 60, 80, 100]}]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3tA34R11kMG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677092698893,"user_tz":300,"elapsed":1016842,"user":{"displayName":"Dongyang Wei","userId":"09161976673543366432"}},"outputId":"be407f07-6427-41c4-e2c3-2d3823cba179"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'max_depth': 100, 'max_features': 8, 'min_samples_leaf': 5}\n"]}],"source":["# -- perform Grid Search\n","rfc_tune = RandomForestRegressor()\n","cv_tune = GridSearchCV(rfc_tune, tuned_parameters, n_jobs=-1)\n","cv_tune.fit(feat_tr, targ_tr)\n","\n","# -- print out the params with the highest \"score\"\n","print(cv_tune.best_params_)"]},{"cell_type":"code","source":["# -- suppress overfitting after using grid search\n","rfr = RandomForestRegressor(max_depth = 100, max_features=8, min_samples_leaf=5, n_estimators=50)\n","rfr.fit(feat_tr, targ_tr)\n","\n","# -- calculate training and testing MSE\n","mse1_tr = mean_squared_error(targ_tr, rfr1.predict(feat_tr))\n","mse1_te = mean_squared_error(targ_te, rfr1.predict(feat_te))\n","\n","print(\"MSE Training : {0}\".format(mse_tr))\n","print(\"MSE Testing  : {0}\".format(mse_te))\n","print(\"variance Training : {0}\".format(targ_tr.var(ddof=0)))\n","print(\"variance Testing  : {0}\".format(targ_te.var(ddof=0)))\n","print('r2 on training sets:', r2_score(targ_tr, rfr.predict(feat_tr)))\n","print('r2 on test sets:', r2_score(targ_te, rfr.predict(feat_te)))"],"metadata":{"id":"0NdulpZ4N7oW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TiNEwEd4e9q"},"outputs":[],"source":["# -- put the feature importances into a DataFrame\n","imp = pd.DataFrame()\n","imp[\"name\"] = feat_tr.columns\n","imp[\"importance\"] = rfr.feature_importances_\n","\n","# -- display all rows\n","pd.set_option(\"display.max_rows\", 100)\n","\n","# -- sort by importance\n","imp = imp.sort_values(\"importance\", ascending=False)\n","\n","# -- make a bar chart of top 5 most important features\n","ax = imp[:5].plot(\"name\", \"importance\", kind=\"bar\", figsize=[7, 7])\n","dum = ax.set_xlabel(\"\")"]}]}